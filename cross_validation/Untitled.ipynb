{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mp\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' PARAMETERS '''\n",
    "# INPUT_FILE = f'{var1}/{var2}'\n",
    "INPUT_FILE = f'enunciado/diabetes.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df, cols):\n",
    "    '''\n",
    "    df: Input dataframe\n",
    "    cols: Columns to normalize\n",
    "    '''\n",
    "    for col in cols:\n",
    "        val_max = max(df[col])\n",
    "        val_min = min(df[col])\n",
    "        df[col] = (df[col] - val_min)/(val_max - val_min)\n",
    "        # print(f'Column: {col}, min: {val_min}, max:{val_max}.')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folds(k=5, df=None, col=''):\n",
    "    \n",
    "    df['fold'] = -1\n",
    "    \n",
    "    df_w_folds = pd.DataFrame(columns=df.columns)\n",
    "    \n",
    "    uniq_class_list = df[col].unique() #[0, 1, 2]\n",
    "    \n",
    "    for val in uniq_class_list:\n",
    "        df_temp = df[df[col] == val]\n",
    "        ar_fold = np.arange(len(df_temp))\n",
    "        random.shuffle(ar_fold)\n",
    "        \n",
    "        # Split array in n folds \n",
    "        f = lambda x: x%k+1\n",
    "        ar_fold = f(ar_fold)\n",
    "        df_temp['fold'] = ar_fold\n",
    "        df_w_folds = df_w_folds.append(df_temp)\n",
    "    \n",
    "    df_w_folds = df_w_folds.sort_values(by=['fold'])\n",
    "    print(df_w_folds.head(30))\n",
    "    return df_w_folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(k_fold, ar_k_knn, df, cols, col_real, beta):\n",
    "    df = get_folds(k_fold, df, col_real)\n",
    "        \n",
    "    labels = df[col_real].unique()\n",
    "    labels.sort()\n",
    "    classes_size = len(labels)\n",
    "    pos_lab_dict = dict(zip(labels, [i for i in range(classes_size)]))    \n",
    "#     print(pos_lab_dict)\n",
    "    for k_knn in ar_k_knn:\n",
    "        print(f'K for k-NN: {k_knn}')\n",
    "        df_out = pd.DataFrame(columns=['fold', 'accuracia', 'f-measure'])\n",
    "        for fold in range(k_fold):\n",
    "            df_train = df[df['fold'] != fold+1]\n",
    "            df_test = df[df['fold'] == fold+1]\n",
    "    #         print(f'df_train: {len(df_train)}, df_test: {len(df_test)}')\n",
    "            ''' create the confusion matrix:\n",
    "            Rows: Real Values\n",
    "            Cols: Predicted Values\n",
    "            '''\n",
    "            confusion_matrix = np.zeros((classes_size, classes_size))\n",
    "\n",
    "            for index, row in df_test.iterrows():\n",
    "                pred = knn(k=k_knn, df_train=df_train, row_test=row, cols=cols, col_real=col_real)\n",
    "                # Get position in the confusion matrix of prediction\n",
    "                col_pred_pos = pos_lab_dict[pred]\n",
    "                row_real_pos = pos_lab_dict[row[col_real]]\n",
    "                confusion_matrix[row_real_pos][col_pred_pos] += 1\n",
    "\n",
    "    #         print(confusion_matrix)\n",
    "\n",
    "            # Diagonal contains the right classification    \n",
    "            acc = np.trace(confusion_matrix)/np.sum(confusion_matrix) \n",
    "            prec_accum = 0\n",
    "            rec_accum = 0\n",
    "    #         for label in labels:\n",
    "            for label in [1]:\n",
    "                pos = pos_lab_dict[label]\n",
    "                # VP/VP+FP\n",
    "                prec_accum = confusion_matrix[pos][pos] / sum( confusion_matrix[i][pos] for i in range(classes_size)) \n",
    "                # VP/VP+FN\n",
    "                rec_accum = confusion_matrix[pos][pos] / sum( confusion_matrix[pos][i] for i in range(classes_size)) \n",
    "\n",
    "            ''' f (macro): The average of all precision and recall: For multiclass '''\n",
    "            prec = prec_accum #/ classes_size\n",
    "            rec = rec_accum #/ classes_size\n",
    "    #         print(f'prec: {prec}, rec: {rec}')\n",
    "            f1 = (1+beta**2)*( (prec*rec) / ((beta**2)*prec + rec ) )\n",
    "            df_out = df_out.append({'fold':(int)(fold+1), 'accuracia': acc, 'f-measure': f1}, ignore_index=True)\n",
    "\n",
    "        print(df_out)\n",
    "        avg_acc = np.average(df_out['accuracia'])\n",
    "        avg_f1 = np.average(df_out['f-measure'])\n",
    "        std_acc = np.std(df_out['accuracia'])\n",
    "        std_f1 = np.std(df_out['f-measure'])\n",
    "\n",
    "        print(f'Average Acc: {avg_acc}, Average f1-measure: {avg_f1}')\n",
    "        print(f'Std Acc: {std_acc}, Std f1-measure: {std_f1}')\n",
    "\n",
    "    #     return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn(k=5, df_train=None, row_test=None, cols=[], col_real=''):\n",
    "    df = df_train.copy()\n",
    "    df['euc_dist'] = 0\n",
    "    for col in cols:\n",
    "        df['euc_dist'] += (df[col]-row_test[col])**2\n",
    "    df['euc_dist'] = np.sqrt(df['euc_dist'])\n",
    "    df = df.sort_values(by=['euc_dist'], ascending=True)\n",
    "    \n",
    "    # Get the k nearest possible values\n",
    "    res_list = df.head(k)[col_real].to_list()\n",
    "    # Return the most repeated element\n",
    "    return max(set(res_list), key = res_list.count)\n",
    "\n",
    "#     print(df.head(k).to_list)\n",
    "#     print(row_test)\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## INIT\n",
    "Call main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Read dataframe '''\n",
    "df = pd.read_csv(INPUT_FILE)\n",
    "# Columns to normalize \n",
    "ar_columns = ['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', \n",
    "              'DiabetesPedigreeFunction', 'Age']\n",
    "df_norm = normalize(df, ar_columns)\n",
    "r = 10\n",
    "ar_k_knn = [3, 5, 7]\n",
    "for i in range(r):\n",
    "    print(f'R: {i+1}')\n",
    "    cross_validation(10, ar_k_knn, df_norm, ar_columns, 'Outcome', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
