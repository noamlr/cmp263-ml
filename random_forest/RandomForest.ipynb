{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import numpy as np\n",
    "import random\n",
    "from math import log2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.is_leaf = data['is_leaf']\n",
    "        self.answer = data['answer']\n",
    "        self.feature_check = data['column'] \n",
    "        self.children_type = '' # if categorical C value_to_check - string, otherwise if Continuous N value_to_check numeric and validate if check_less\n",
    "        self.value_to_check = data['value_to_check']\n",
    "        self.check_less = data['check_less']\n",
    "        self.children = [] ## just two if n_type = N (numerical) [less, greater or equal]\n",
    "    \n",
    "    def set_children_type(self, value):\n",
    "        self.children_type = value\n",
    "        \n",
    "    def set_is_leaf(self, value):\n",
    "        self.is_leaf = value\n",
    "    \n",
    "    def get_children(self):\n",
    "        return self.children\n",
    "    \n",
    "    def insert_node(self, node):\n",
    "        # self.children = self.children.append(node) \n",
    "        self.children.append(node) \n",
    "    \n",
    "    def get_classification(self, row):\n",
    "        if self.is_leaf: \n",
    "            return self.answer\n",
    "        else:\n",
    "            '''Categorical'''\n",
    "            if self.children_type == 'C':\n",
    "                for child in self.children:\n",
    "                    print(f'feature_check: {child.feature_check}')\n",
    "                    if row[child.feature_check] == child.value_to_check:\n",
    "                        return child.get_classification(row)\n",
    "            else:\n",
    "                '''Numerical'''\n",
    "                if row[child.feature_check] < child[0].value_to_check:\n",
    "                    return child[0].get_classification(row)\n",
    "                else:\n",
    "                    return child[1].get_classification(row)\n",
    "    \n",
    "    def print_tree(self, level=0):\n",
    "        print(f'lvl:{level}, Leaf: {self.is_leaf}, type: {self.children_type}, feature_check: {self.feature_check}, check: {self.value_to_check}')\n",
    "        if self.is_leaf:\n",
    "            print(f'lvl:{level}, answer: {self.answer}\\n\\n')\n",
    "        else:\n",
    "            for child in self.children:\n",
    "                child.print_tree(level=level+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    data = pd.DataFrame()\n",
    "    categorical_features = []\n",
    "    continuous_features = []\n",
    "    yaml_structure = {}\n",
    "    target_feature = ''\n",
    "    target_type = ''\n",
    "\n",
    "    '''\n",
    "    Load the CSV/TSV file, saves it in data\n",
    "    '''\n",
    "    def load_dataset(self, input_path, separator):\n",
    "        self.data = pd.read_csv(input_path, sep=separator)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Read the structure and get the types of the columns in two list [categorical, coninuous]\n",
    "    Set target_column and target_type\n",
    "    '''\n",
    "    def read_structure(self, input_file, target_column):\n",
    "        with open(input_file) as f:\n",
    "            self.yaml_structure = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        self.target_feature = target_column\n",
    "        self.target_type = self.yaml_structure['target']['type']\n",
    "        \n",
    "        self.categorical_features = []\n",
    "        self.continuous_features = []\n",
    "        \n",
    "        for feature in self.yaml_structure['features']:\n",
    "            if feature['type'] == 'continuous':\n",
    "                n_min = min(self.data[feature['name']])\n",
    "                n_diff = max(self.data[feature['name']]) - n_min\n",
    "                if n_diff != 0:\n",
    "                    self.data[feature['name']] = (self.data[feature['name']] - n_min) / n_diff\n",
    "                self.continuous_features.append({'name': feature['name'], 'min': n_min, 'diff': n_diff })\n",
    "                \n",
    "            else:\n",
    "                self.categorical_features.append({'name': feature['name']})\n",
    "\n",
    "    \n",
    "    '''\n",
    "    Initialization\n",
    "    '''\n",
    "    def __init__(self, file_dataset_path, file_structure_path, char_separator='\\t', target_column='target'):\n",
    "        self.load_dataset(file_dataset_path, char_separator)\n",
    "        self.read_structure(file_structure_path, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gain_ratio(df, TGT_COL='target', EVAL_COL='', CATEGORICAL=False):\n",
    "#     print(df)\n",
    "    uniq_tgts = df[TGT_COL].unique()\n",
    "    uniq_d_a_vals = df[EVAL_COL].unique() #uniq_evals\n",
    "    len_d_tot = len(df)\n",
    "    \n",
    "    # Validate if len(df)>0, else return 0\n",
    "    if len_d_tot == 0: return 0\n",
    "    \n",
    "    sel_cut_point = None\n",
    "    \n",
    "    inf_d_tot = 0\n",
    "    for curr_tgt in uniq_tgts:\n",
    "        curr_len = len(df.loc[df[TGT_COL] ==curr_tgt])\n",
    "        if curr_len!=0:\n",
    "            inf_d_tot -= (curr_len/len_d_tot)*log2(curr_len/len_d_tot) ## Respect to Target Column\n",
    "    \n",
    "    gain_ratio_a = 0\n",
    "    if CATEGORICAL is True:\n",
    "        inf_d_a = 0\n",
    "        split_info_a = 0\n",
    "        for curr_d_aj in uniq_d_a_vals: #curr_eval\n",
    "            '''Gain A: Begin'''\n",
    "            len_d_aj = len(df[df[EVAL_COL] == curr_d_aj]) #len_eval\n",
    "            inf_d_aj = 0\n",
    "            for curr_tgt in uniq_tgts:\n",
    "                curr_len = len(df.loc[(df[EVAL_COL] == curr_d_aj) & (df[TGT_COL] ==curr_tgt)])\n",
    "                if curr_len != 0 and len_d_aj != 0:\n",
    "                    inf_d_aj -= (curr_len/len_d_aj)*log2(curr_len/len_d_aj)\n",
    "    #         print(f'curr_val: {curr_eval}, value: {curr_info}')\n",
    "            inf_d_a += (len_d_aj/len_d_tot)*inf_d_aj\n",
    "            '''Gain A: End'''\n",
    "            '''Split Info A: Begin'''\n",
    "            if len_d_aj != 0 and len_d_tot != 0:\n",
    "                split_info_a -= (len_d_aj/len_d_tot)*log2(len_d_aj/len_d_tot)  ## Respect to column to be split\n",
    "            '''Split Info A: End'''\n",
    "        gain_a = inf_d_tot - inf_d_a\n",
    "        if split_info_a != 0:\n",
    "            gain_ratio_a = gain_a / split_info_a\n",
    "        else:\n",
    "            gain_ratio_a = 0\n",
    "        print(f'{EVAL_COL}:   inf_d_tot: {inf_d_tot}, inf_d_a: {inf_d_a}, gain_a: {gain_a}, split_info_a: {split_info_a}, gain_ratio: {gain_ratio_a}')\n",
    "    else: \n",
    "        ### Mean for cut point:\n",
    "        mean_val_point = df[EVAL_COL].mean()\n",
    "    \n",
    "#         for curr_cut_point in qt_points:\n",
    "        inf_d_a = 0\n",
    "        split_info_a = 0\n",
    "        '''Gain A: Begin'''\n",
    "        '''    < cut_point '''\n",
    "        len_d_aj = len(df[df[EVAL_COL] < mean_val_point]) #len_eval\n",
    "        inf_d_aj = 0\n",
    "        for curr_tgt in uniq_tgts:\n",
    "            curr_len = len(df.loc[(df[EVAL_COL] < mean_val_point) & (df[TGT_COL] ==curr_tgt)])\n",
    "            if curr_len != 0 and len_d_aj != 0:\n",
    "                inf_d_aj -= (curr_len/len_d_aj)*log2(curr_len/len_d_aj)\n",
    "#         print(f'curr_val: {curr_eval}, value: {curr_info}')\n",
    "        inf_d_a += (len_d_aj/len_d_tot)*inf_d_aj\n",
    "        '''   >= cut_point '''\n",
    "        len_d_aj =  len_d_tot - len_d_aj\n",
    "        inf_d_aj = 0\n",
    "        for curr_tgt in uniq_tgts:\n",
    "            curr_len = len(df.loc[(df[EVAL_COL] >= mean_val_point) & (df[TGT_COL] ==curr_tgt)])\n",
    "            if curr_len != 0 and len_d_aj != 0:\n",
    "                inf_d_aj -= (curr_len/len_d_aj)*log2(curr_len/len_d_aj)\n",
    "#         print(f'curr_val: {curr_eval}, value: {curr_info}')\n",
    "        inf_d_a += (len_d_aj/len_d_tot)*inf_d_aj\n",
    "        '''Gain A: End'''\n",
    "        '''Split Info A: Begin'''\n",
    "        if len_d_aj != 0 and len_d_tot != 0:\n",
    "            len_d_aj = len(df[df[EVAL_COL] < mean_val_point]) #len_eval\n",
    "            split_info_a -= (len_d_aj/len_d_tot)*log2(len_d_aj/len_d_tot)\n",
    "            len_d_aj = len_d_tot - len_d_aj\n",
    "            split_info_a -= (len_d_aj/len_d_tot)*log2(len_d_aj/len_d_tot)\n",
    "        '''Split Info A: End'''\n",
    "        gain_a = inf_d_tot - inf_d_a\n",
    "        if split_info_a != 0: \n",
    "            gain_ratio_a = gain_a / split_info_a\n",
    "        else:\n",
    "            gain_ratio_a = 0\n",
    "        sel_cut_point = mean_val_point\n",
    "        print(f'For cut_point: {mean_val_point}, inf_d_tot: {inf_d_tot}, inf_d_a: {inf_d_a}, gain_a: {gain_a}, split_info_a: {split_info_a}, gain_ratio: {gain_ratio_a}')\n",
    "        \n",
    "        \n",
    "        \n",
    "        ''' TRY TO FIND A POINT FOR SPLIT THE DATA '''\n",
    "#         ### Possible cut points:\n",
    "#         df.sort_values(by=[EVAL_COL])\n",
    "#         cand_points = []\n",
    "#         qt_points = []\n",
    "#         last_row = None\n",
    "#         # mask = (df[df[TGT_COL].shift(1) != df[TGT_COL]])\n",
    "#         np_lbls = np.array(df[TGT_COL])\n",
    "#         np_numb = np.array(df[EVAL_COL])\n",
    "#         print(np_lbls)\n",
    "#         print(np_numb)\n",
    "#         for idx in range(1, np_lbls.shape[0]):\n",
    "#             if np_lbls[idx] != np_lbls[idx-1]:\n",
    "#                 cand_points = np.append(cand_points, (np_numb[idx]+np_numb[idx-1])/2)\n",
    "#         print(cand_points)\n",
    "#         if cand_points.shape[0] < 4:\n",
    "#             qt_points = cand_points\n",
    "#         else:\n",
    "#             len_cand = cand_points.shape[0]\n",
    "#             qt_points = np.append(qt_points, cand_points[(int)(len_cand/4)])\n",
    "#             qt_points = np.append(qt_points, cand_points[(int)(len_cand/2)])\n",
    "#             qt_points = np.append(qt_points, cand_points[(int)(3*len_cand/4)])\n",
    "        \n",
    "    \n",
    "#         for curr_cut_point in qt_points:\n",
    "#             inf_d_a = 0\n",
    "#             split_info_a = 0\n",
    "#             '''Gain A: Begin'''\n",
    "#             '''    < cut_point '''\n",
    "#             len_d_aj = len(df[df[EVAL_COL] < curr_cut_point]) #len_eval\n",
    "#             inf_d_aj = 0\n",
    "#             for curr_tgt in uniq_tgts:\n",
    "#                 curr_len = len(df.loc[(df[EVAL_COL] < curr_cut_point) & (df[TGT_COL] ==curr_tgt)])\n",
    "#                 if curr_len != 0 and len_d_aj != 0:\n",
    "#                     inf_d_aj -= (curr_len/len_d_aj)*log2(curr_len/len_d_aj)\n",
    "#     #         print(f'curr_val: {curr_eval}, value: {curr_info}')\n",
    "#             inf_d_a += (len_d_aj/len_d_tot)*inf_d_aj\n",
    "#             '''   >= cut_point '''\n",
    "#             len_d_aj =  len_d_tot - len_d_aj\n",
    "#             inf_d_aj = 0\n",
    "#             for curr_tgt in uniq_tgts:\n",
    "#                 curr_len = len(df.loc[(df[EVAL_COL] >= curr_cut_point) & (df[TGT_COL] ==curr_tgt)])\n",
    "#                 if curr_len != 0 and len_d_aj != 0:\n",
    "#                     inf_d_aj -= (curr_len/len_d_aj)*log2(curr_len/len_d_aj)\n",
    "#     #         print(f'curr_val: {curr_eval}, value: {curr_info}')\n",
    "#             inf_d_a += (len_d_aj/len_d_tot)*inf_d_aj\n",
    "#             '''Gain A: End'''\n",
    "#             '''Split Info A: Begin'''\n",
    "#             if len_d_aj != 0 and len_d_tot != 0:\n",
    "#                 len_d_aj = len(df[df[EVAL_COL] < curr_cut_point]) #len_eval\n",
    "#                 split_info_a -= (len_d_aj/len_d_tot)*log2(len_d_aj/len_d_tot)\n",
    "#                 len_d_aj = len_d_tot - len_d_aj\n",
    "#                 split_info_a -= (len_d_aj/len_d_tot)*log2(len_d_aj/len_d_tot)\n",
    "#             '''Split Info A: End'''\n",
    "#             gain_a = inf_d_tot - inf_d_a\n",
    "#             gain_ratio_a_temp = gain_a / split_info_a\n",
    "#             if gain_ratio_a < gain_ratio_a_temp:\n",
    "#                 gain_ratio_a = gain_ratio_a_temp\n",
    "#                 sel_cut_point = curr_cut_point\n",
    "#             print(f'For cut_point: {curr_cut_point}, inf_d_tot: {inf_d_tot}, inf_d_a: {inf_d_a}, gain_a: {gain_a}, split_info_a: {split_info_a}, gain_ratio: {gain_ratio_a_temp}')\n",
    "            \n",
    "    return (gain_ratio_a, sel_cut_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "cols: [(nom_col, True), (nom_col1, True), (nom_col2, False) ... ]  ........ True if categorical, Otherwise False\n",
    "'''\n",
    "def select_best_column(df, tgt_col='target', cols=[]):\n",
    "    best_param = ('None', 0, 0)\n",
    "    rand_cols = random.sample(cols, k=2)\n",
    "    print(f'rand_cols: {rand_cols}')\n",
    "    for col in rand_cols:\n",
    "        curr_entr, cut_point = get_gain_ratio(df, TGT_COL=tgt_col, EVAL_COL=col[0], CATEGORICAL=col[1])\n",
    "        if best_param[2] <= curr_entr:\n",
    "            best_param = (col[0], cut_point, curr_entr)\n",
    "    return best_param\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Dataset at 0x7fd9f4333748>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_PATH = 'data/own_test_benchmark/test_benchmark.csv'\n",
    "STRUCTURE_PATH = 'data/own_test_benchmark/metadata.yaml'\n",
    "obj = Dataset(INPUT_PATH, STRUCTURE_PATH, ';', 'target')\n",
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Tempo', True),\n",
       " ('Temperatura', True),\n",
       " ('Umidade', True),\n",
       " ('Ventoso', True),\n",
       " ('Probabilidade', False)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = []\n",
    "cols = cols + (list(zip([j['name'] for j in obj.categorical_features], [True for i in range(len(obj.categorical_features))])))\n",
    "cols = cols + (list(zip([j['name'] for j in obj.continuous_features], [False for i in range(len(obj.continuous_features))])))\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rand_cols: [('Ventoso', True), ('Probabilidade', False)]\n",
      "Ventoso:   inf_d_tot: 0.9402859586706309, inf_d_a: 0.8921589282623617, gain_a: 0.04812703040826927, split_info_a: 0.9852281360342515, gain_ratio: 0.0488486155115206\n",
      "For cut_point: 0.3910714285714286, inf_d_tot: 0.9402859586706309, inf_d_a: 0.850009609277866, gain_a: 0.09027634939276497, split_info_a: 0.9852281360342515, gain_ratio: 0.09162989371796271\n",
      "best_param: ('Probabilidade', 0.3910714285714286, 0.09162989371796271)\n",
      "new_cols: [('Tempo', True), ('Temperatura', True), ('Umidade', True), ('Ventoso', True)]\n",
      "rand_cols: [('Tempo', True), ('Temperatura', True)]\n",
      "Tempo:   inf_d_tot: 1.0, inf_d_a: 0.3443609377704336, gain_a: 0.6556390622295665, split_info_a: 1.561278124459133, gain_ratio: 0.41993739101205735\n",
      "Temperatura:   inf_d_tot: 1.0, inf_d_a: 0.9387218755408671, gain_a: 0.06127812445913294, split_info_a: 1.561278124459133, gain_ratio: 0.03924869214468836\n",
      "best_param: ('Tempo', None, 0.41993739101205735)\n",
      "rand_cols: [('Ventoso', True), ('Temperatura', True)]\n",
      "Ventoso:   inf_d_tot: 0.9182958340544896, inf_d_a: 0.0, gain_a: 0.9182958340544896, split_info_a: 0.9182958340544896, gain_ratio: 1.0\n",
      "Temperatura:   inf_d_tot: 0.9182958340544896, inf_d_a: 0.6666666666666666, gain_a: 0.2516291673878229, split_info_a: 0.9182958340544896, gain_ratio: 0.274017542121281\n",
      "best_param: ('Ventoso', None, 1.0)\n",
      "best_param: ('Ventoso', None, 1.0)\n",
      "best_param: ('Tempo', None, 0.41993739101205735)\n",
      "rand_cols: [('Ventoso', True), ('Temperatura', True)]\n",
      "Ventoso:   inf_d_tot: 0.6500224216483541, inf_d_a: 0.4591479170272448, gain_a: 0.19087450462110933, split_info_a: 1.0, gain_ratio: 0.19087450462110933\n",
      "Temperatura:   inf_d_tot: 0.6500224216483541, inf_d_a: 0.5408520829727552, gain_a: 0.10917033867559889, split_info_a: 1.2516291673878228, gain_ratio: 0.08722259078017473\n",
      "best_param: ('Ventoso', None, 0.19087450462110933)\n",
      "rand_cols: [('Tempo', True), ('Temperatura', True)]\n",
      "Tempo:   inf_d_tot: 0.9182958340544896, inf_d_a: 0.0, gain_a: 0.9182958340544896, split_info_a: 1.584962500721156, gain_ratio: 0.579380164285695\n",
      "Temperatura:   inf_d_tot: 0.9182958340544896, inf_d_a: 0.9182958340544896, gain_a: 0.0, split_info_a: 0.0, gain_ratio: 0\n",
      "best_param: ('Tempo', None, 0.579380164285695)\n",
      "best_param: ('Tempo', None, 0.579380164285695)\n",
      "best_param: ('Ventoso', None, 0.19087450462110933)\n",
      "best_param: ('Probabilidade', 0.3910714285714286, 0.09162989371796271)\n",
      "lvl:0, Leaf: False, type: N, feature_check: None, check: None\n",
      "lvl:1, Leaf: False, type: C, feature_check: Probabilidade, check: 0.3910714285714286\n",
      "lvl:2, Leaf: True, type: , feature_check: Tempo, check: Ensolarado\n",
      "lvl:2, answer: Nao\n",
      "\n",
      "\n",
      "lvl:2, Leaf: True, type: , feature_check: Tempo, check: Nublado\n",
      "lvl:2, answer: Sim\n",
      "\n",
      "\n",
      "lvl:2, Leaf: False, type: C, feature_check: Tempo, check: Chuvoso\n",
      "lvl:3, Leaf: True, type: , feature_check: Ventoso, check: Falso\n",
      "lvl:3, answer: Sim\n",
      "\n",
      "\n",
      "lvl:3, Leaf: True, type: , feature_check: Ventoso, check: Verdadeiro\n",
      "lvl:3, answer: Nao\n",
      "\n",
      "\n",
      "lvl:1, Leaf: False, type: C, feature_check: Probabilidade, check: 0.3910714285714286\n",
      "lvl:2, Leaf: True, type: , feature_check: Ventoso, check: Falso\n",
      "lvl:2, answer: Sim\n",
      "\n",
      "\n",
      "lvl:2, Leaf: False, type: C, feature_check: Ventoso, check: Verdadeiro\n",
      "lvl:3, Leaf: True, type: , feature_check: Tempo, check: Ensolarado\n",
      "lvl:3, answer: Sim\n",
      "\n",
      "\n",
      "lvl:3, Leaf: True, type: , feature_check: Tempo, check: Nublado\n",
      "lvl:3, answer: Sim\n",
      "\n",
      "\n",
      "lvl:3, Leaf: True, type: , feature_check: Tempo, check: Chuvoso\n",
      "lvl:3, answer: Nao\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# del data_root, root_node\n",
    "data_root = {'is_leaf': False, 'answer': None, 'column': None, 'value_to_check': None, 'check_less': None}\n",
    "    \n",
    "root_node = Node(data_root)\n",
    "\n",
    "def build_tree(parent_node, df, tgt_col, cols):\n",
    "#     print(df)\n",
    "    # (col_name, cut_point, score)\n",
    "    best_param = select_best_column(df, tgt_col=tgt_col, cols=cols)\n",
    "    print(f'best_param: {best_param}')\n",
    "    '''Numerical'''\n",
    "    if best_param[1] is not None: # Numerical\n",
    "        parent_node.set_children_type('N')\n",
    "        \n",
    "        new_cols = []\n",
    "        for c in cols:\n",
    "            if c[0] != best_param[0]:\n",
    "                new_cols.append(c)\n",
    "        print(f'new_cols: {new_cols}')\n",
    "        \n",
    "        ''' Left child '''\n",
    "        df_temp = df[df[best_param[0]] < best_param[1]]\n",
    "        data_temp = {'is_leaf': False, 'answer': None, 'column': best_param[0], 'value_to_check': best_param[1], 'check_less': True}\n",
    "        tgt_uniq_vals = df_temp[tgt_col].unique()\n",
    "\n",
    "        if (len(tgt_uniq_vals) == 1):  # Is leaf\n",
    "            data_temp['is_leaf'] = True\n",
    "            data_temp['answer'] = tgt_uniq_vals[0]\n",
    "\n",
    "        node_temp = Node(data_temp)\n",
    "        parent_node.insert_node(node_temp)\n",
    "\n",
    "        if (len(tgt_uniq_vals) > 1):\n",
    "            build_tree(node_temp, df_temp, tgt_col, new_cols)\n",
    "            \n",
    "        ''' Right child '''\n",
    "        df_temp = df[df[best_param[0]] >= best_param[1]]\n",
    "        data_temp = {'is_leaf': False, 'answer': None, 'column': best_param[0], 'value_to_check': best_param[1], 'check_less': False}\n",
    "        tgt_uniq_vals = df_temp[tgt_col].unique()\n",
    "\n",
    "        if (len(tgt_uniq_vals) == 1):  # Is leaf\n",
    "            data_temp['is_leaf'] = True\n",
    "            data_temp['answer'] = tgt_uniq_vals[0]\n",
    "\n",
    "        node_temp = Node(data_temp)\n",
    "        parent_node.insert_node(node_temp)\n",
    "\n",
    "        if (len(tgt_uniq_vals) > 1):\n",
    "            build_tree(node_temp, df_temp, tgt_col, new_cols)\n",
    "    else:\n",
    "        '''Categorical'''\n",
    "        parent_node.set_children_type('C')\n",
    "        uniq_vals = df[best_param[0]].unique()\n",
    "        \n",
    "        new_cols = []\n",
    "        for c in cols:\n",
    "            if c[0] != best_param[0]:\n",
    "                new_cols.append(c)\n",
    "#         print(f'new_cols: {new_cols}')\n",
    "        \n",
    "        for val in uniq_vals:\n",
    "            df_temp = df[df[best_param[0]] == val]\n",
    "            data_temp = {'is_leaf': False, 'answer': None, 'column': best_param[0], 'value_to_check': val, 'check_less': None}\n",
    "            tgt_uniq_vals = df_temp[tgt_col].unique()\n",
    "            \n",
    "            if (len(tgt_uniq_vals) == 1):  # Is leaf\n",
    "                data_temp['is_leaf'] = True\n",
    "                data_temp['answer'] = tgt_uniq_vals[0]\n",
    "            \n",
    "            node_temp = Node(data_temp)\n",
    "            parent_node.insert_node(node_temp)\n",
    "            \n",
    "            if (len(tgt_uniq_vals) > 1):\n",
    "                build_tree(node_temp, df_temp, tgt_col, new_cols)\n",
    "        \n",
    "    print(f'best_param: {best_param}')\n",
    "\n",
    "\n",
    "build_tree(root_node, obj.data.copy(), 'target', cols)\n",
    "root_node.print_tree(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_check: Umidade\n",
      "feature_check: Tempo\n",
      "feature_check: Tempo\n",
      "feature_check: Tempo\n",
      "feature_check: Ventoso\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Sim'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = {'Tempo': 'Chuvoso', 'Temperatura': 'Amena', 'Umidade': 'Alta', 'Ventoso': 'Falso', 'Probabilidade': 16}\n",
    "root_node.get_classification(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
