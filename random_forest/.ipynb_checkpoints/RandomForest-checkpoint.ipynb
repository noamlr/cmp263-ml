{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import numpy as np\n",
    "import random\n",
    "from math import log2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node():\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.is_leaf = data['is_leaf']\n",
    "        self.answer = data['answer']\n",
    "        self.feature_check = data['column'] \n",
    "        self.children_type = '' # if categorical C value_to_check - string, otherwise if Continuous N value_to_check numeric and validate if check_less\n",
    "        self.value_to_check = data['value_to_check']\n",
    "        self.check_less = data['check_less']\n",
    "        self.children = [] ## just two if n_type = N (numerical) [less, greater or equal]\n",
    "    \n",
    "    def set_children_type(self, value):\n",
    "        self.children_type = value\n",
    "        \n",
    "    def set_is_leaf(self, value):\n",
    "        self.is_leaf = value\n",
    "    \n",
    "    def get_children(self):\n",
    "        return self.children\n",
    "    \n",
    "    def insert_node(self, node):\n",
    "        # self.children = self.children.append(node) \n",
    "        self.children.append(node) \n",
    "    \n",
    "    def get_classification(self, row):\n",
    "        if self.is_leaf: \n",
    "            return self.answer\n",
    "        else:\n",
    "            '''Categorical'''\n",
    "            if self.children_type == 'C':\n",
    "                for child in self.children:\n",
    "                    print(f'feature_check: {child.feature_check}')\n",
    "                    if row[child.feature_check] == child.value_to_check:\n",
    "                        return child.get_classification(row)\n",
    "            else:\n",
    "                '''Numerical'''\n",
    "                if row[child.feature_check] < child[0].value_to_check:\n",
    "                    return child[0].get_classification(row)\n",
    "                else:\n",
    "                    return child[1].get_classification(row)\n",
    "    \n",
    "    def print_tree(self, level=0):\n",
    "        print(f'lvl:{level}, Leaf: {self.is_leaf}, type: {self.children_type}, feature_check: {self.feature_check}, check: {self.value_to_check}')\n",
    "        if self.is_leaf:\n",
    "            print(f'lvl:{level}, answer: {self.answer}\\n\\n')\n",
    "        else:\n",
    "            for child in self.children:\n",
    "                child.print_tree(level=level+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    data = pd.DataFrame()\n",
    "    categorical_features = []\n",
    "    continuous_features = []\n",
    "    yaml_structure = {}\n",
    "    target_feature = ''\n",
    "    target_type = ''\n",
    "\n",
    "    '''\n",
    "    Load the CSV/TSV file, saves it in data\n",
    "    '''\n",
    "    def load_dataset(self, input_path, separator):\n",
    "        self.data = pd.read_csv(input_path, sep=separator)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Read the structure and get the types of the columns in two list [categorical, coninuous]\n",
    "    Set target_column and target_type\n",
    "    '''\n",
    "    def read_structure(self, input_file, target_column):\n",
    "        with open(input_file) as f:\n",
    "            self.yaml_structure = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        self.target_feature = target_column\n",
    "        self.target_type = self.yaml_structure['target']['type']\n",
    "        \n",
    "        self.categorical_features = []\n",
    "        self.continuous_features = []\n",
    "        \n",
    "        for feature in self.yaml_structure['features']:\n",
    "            if feature['type'] == 'continuous':\n",
    "                n_min = min(self.data[feature['name']])\n",
    "                n_diff = max(self.data[feature['name']]) - n_min\n",
    "                if n_diff != 0:\n",
    "                    self.data[feature['name']] = (self.data[feature['name']] - n_min) / n_diff\n",
    "                self.continuous_features.append({'name': feature['name'], 'min': n_min, 'diff': n_diff })\n",
    "                \n",
    "            else:\n",
    "                self.categorical_features.append({'name': feature['name']})\n",
    "\n",
    "    \n",
    "    '''\n",
    "    Initialization\n",
    "    '''\n",
    "    def __init__(self, file_dataset_path, file_structure_path, char_separator='\\t', target_column='target'):\n",
    "        self.load_dataset(file_dataset_path, char_separator)\n",
    "        self.read_structure(file_structure_path, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gain_ratio(df, TGT_COL='target', EVAL_COL='', CATEGORICAL=False):\n",
    "#     print(df)\n",
    "    uniq_tgts = df[TGT_COL].unique()\n",
    "    uniq_d_a_vals = df[EVAL_COL].unique() #uniq_evals\n",
    "    len_d_tot = len(df)\n",
    "    \n",
    "    # Validate if len(df)>0, else return 0\n",
    "    if len_d_tot == 0: return 0\n",
    "    \n",
    "    sel_cut_point = None\n",
    "    \n",
    "    inf_d_tot = 0\n",
    "    for curr_tgt in uniq_tgts:\n",
    "        curr_len = len(df.loc[df[TGT_COL] ==curr_tgt])\n",
    "        if curr_len!=0:\n",
    "            inf_d_tot -= (curr_len/len_d_tot)*log2(curr_len/len_d_tot) ## Respect to Target Column\n",
    "    \n",
    "    gain_ratio_a = 0\n",
    "    if CATEGORICAL is True:\n",
    "        inf_d_a = 0\n",
    "        split_info_a = 0\n",
    "        for curr_d_aj in uniq_d_a_vals: #curr_eval\n",
    "            '''Gain A: Begin'''\n",
    "            len_d_aj = len(df[df[EVAL_COL] == curr_d_aj]) #len_eval\n",
    "            inf_d_aj = 0\n",
    "            for curr_tgt in uniq_tgts:\n",
    "                curr_len = len(df.loc[(df[EVAL_COL] == curr_d_aj) & (df[TGT_COL] ==curr_tgt)])\n",
    "                if curr_len != 0 and len_d_aj != 0:\n",
    "                    inf_d_aj -= (curr_len/len_d_aj)*log2(curr_len/len_d_aj)\n",
    "    #         print(f'curr_val: {curr_eval}, value: {curr_info}')\n",
    "            inf_d_a += (len_d_aj/len_d_tot)*inf_d_aj\n",
    "            '''Gain A: End'''\n",
    "            '''Split Info A: Begin'''\n",
    "            if len_d_aj != 0 and len_d_tot != 0:\n",
    "                split_info_a -= (len_d_aj/len_d_tot)*log2(len_d_aj/len_d_tot)  ## Respect to column to be split\n",
    "            '''Split Info A: End'''\n",
    "        gain_a = inf_d_tot - inf_d_a\n",
    "        if split_info_a != 0:\n",
    "            gain_ratio_a = gain_a / split_info_a\n",
    "        else:\n",
    "            gain_ratio_a = 0\n",
    "        print(f'{EVAL_COL}:   inf_d_tot: {inf_d_tot}, inf_d_a: {inf_d_a}, gain_a: {gain_a}, split_info_a: {split_info_a}, gain_ratio: {gain_ratio_a}')\n",
    "    else: \n",
    "        ### Mean for cut point:\n",
    "        mean_val_point = df[EVAL_COL].mean()\n",
    "    \n",
    "#         for curr_cut_point in qt_points:\n",
    "        inf_d_a = 0\n",
    "        split_info_a = 0\n",
    "        '''Gain A: Begin'''\n",
    "        '''    < cut_point '''\n",
    "        len_d_aj = len(df[df[EVAL_COL] < mean_val_point]) #len_eval\n",
    "        inf_d_aj = 0\n",
    "        for curr_tgt in uniq_tgts:\n",
    "            curr_len = len(df.loc[(df[EVAL_COL] < mean_val_point) & (df[TGT_COL] ==curr_tgt)])\n",
    "            if curr_len != 0 and len_d_aj != 0:\n",
    "                inf_d_aj -= (curr_len/len_d_aj)*log2(curr_len/len_d_aj)\n",
    "#         print(f'curr_val: {curr_eval}, value: {curr_info}')\n",
    "        inf_d_a += (len_d_aj/len_d_tot)*inf_d_aj\n",
    "        '''   >= cut_point '''\n",
    "        len_d_aj =  len_d_tot - len_d_aj\n",
    "        inf_d_aj = 0\n",
    "        for curr_tgt in uniq_tgts:\n",
    "            curr_len = len(df.loc[(df[EVAL_COL] >= mean_val_point) & (df[TGT_COL] ==curr_tgt)])\n",
    "            if curr_len != 0 and len_d_aj != 0:\n",
    "                inf_d_aj -= (curr_len/len_d_aj)*log2(curr_len/len_d_aj)\n",
    "#         print(f'curr_val: {curr_eval}, value: {curr_info}')\n",
    "        inf_d_a += (len_d_aj/len_d_tot)*inf_d_aj\n",
    "        '''Gain A: End'''\n",
    "        '''Split Info A: Begin'''\n",
    "        if len_d_aj != 0 and len_d_tot != 0:\n",
    "            len_d_aj = len(df[df[EVAL_COL] < mean_val_point]) #len_eval\n",
    "            split_info_a -= (len_d_aj/len_d_tot)*log2(len_d_aj/len_d_tot)\n",
    "            len_d_aj = len_d_tot - len_d_aj\n",
    "            split_info_a -= (len_d_aj/len_d_tot)*log2(len_d_aj/len_d_tot)\n",
    "        '''Split Info A: End'''\n",
    "        gain_a = inf_d_tot - inf_d_a\n",
    "        if split_info_a != 0: \n",
    "            gain_ratio_a = gain_a / split_info_a\n",
    "        else:\n",
    "            gain_ratio_a = 0\n",
    "        sel_cut_point = mean_val_point\n",
    "        print(f'For cut_point: {mean_val_point}, inf_d_tot: {inf_d_tot}, inf_d_a: {inf_d_a}, gain_a: {gain_a}, split_info_a: {split_info_a}, gain_ratio: {gain_ratio_a}')\n",
    "        \n",
    "        \n",
    "        \n",
    "        ''' TRY TO FIND A POINT FOR SPLIT THE DATA '''\n",
    "#         ### Possible cut points:\n",
    "#         df.sort_values(by=[EVAL_COL])\n",
    "#         cand_points = []\n",
    "#         qt_points = []\n",
    "#         last_row = None\n",
    "#         # mask = (df[df[TGT_COL].shift(1) != df[TGT_COL]])\n",
    "#         np_lbls = np.array(df[TGT_COL])\n",
    "#         np_numb = np.array(df[EVAL_COL])\n",
    "#         print(np_lbls)\n",
    "#         print(np_numb)\n",
    "#         for idx in range(1, np_lbls.shape[0]):\n",
    "#             if np_lbls[idx] != np_lbls[idx-1]:\n",
    "#                 cand_points = np.append(cand_points, (np_numb[idx]+np_numb[idx-1])/2)\n",
    "#         print(cand_points)\n",
    "#         if cand_points.shape[0] < 4:\n",
    "#             qt_points = cand_points\n",
    "#         else:\n",
    "#             len_cand = cand_points.shape[0]\n",
    "#             qt_points = np.append(qt_points, cand_points[(int)(len_cand/4)])\n",
    "#             qt_points = np.append(qt_points, cand_points[(int)(len_cand/2)])\n",
    "#             qt_points = np.append(qt_points, cand_points[(int)(3*len_cand/4)])\n",
    "        \n",
    "    \n",
    "#         for curr_cut_point in qt_points:\n",
    "#             inf_d_a = 0\n",
    "#             split_info_a = 0\n",
    "#             '''Gain A: Begin'''\n",
    "#             '''    < cut_point '''\n",
    "#             len_d_aj = len(df[df[EVAL_COL] < curr_cut_point]) #len_eval\n",
    "#             inf_d_aj = 0\n",
    "#             for curr_tgt in uniq_tgts:\n",
    "#                 curr_len = len(df.loc[(df[EVAL_COL] < curr_cut_point) & (df[TGT_COL] ==curr_tgt)])\n",
    "#                 if curr_len != 0 and len_d_aj != 0:\n",
    "#                     inf_d_aj -= (curr_len/len_d_aj)*log2(curr_len/len_d_aj)\n",
    "#     #         print(f'curr_val: {curr_eval}, value: {curr_info}')\n",
    "#             inf_d_a += (len_d_aj/len_d_tot)*inf_d_aj\n",
    "#             '''   >= cut_point '''\n",
    "#             len_d_aj =  len_d_tot - len_d_aj\n",
    "#             inf_d_aj = 0\n",
    "#             for curr_tgt in uniq_tgts:\n",
    "#                 curr_len = len(df.loc[(df[EVAL_COL] >= curr_cut_point) & (df[TGT_COL] ==curr_tgt)])\n",
    "#                 if curr_len != 0 and len_d_aj != 0:\n",
    "#                     inf_d_aj -= (curr_len/len_d_aj)*log2(curr_len/len_d_aj)\n",
    "#     #         print(f'curr_val: {curr_eval}, value: {curr_info}')\n",
    "#             inf_d_a += (len_d_aj/len_d_tot)*inf_d_aj\n",
    "#             '''Gain A: End'''\n",
    "#             '''Split Info A: Begin'''\n",
    "#             if len_d_aj != 0 and len_d_tot != 0:\n",
    "#                 len_d_aj = len(df[df[EVAL_COL] < curr_cut_point]) #len_eval\n",
    "#                 split_info_a -= (len_d_aj/len_d_tot)*log2(len_d_aj/len_d_tot)\n",
    "#                 len_d_aj = len_d_tot - len_d_aj\n",
    "#                 split_info_a -= (len_d_aj/len_d_tot)*log2(len_d_aj/len_d_tot)\n",
    "#             '''Split Info A: End'''\n",
    "#             gain_a = inf_d_tot - inf_d_a\n",
    "#             gain_ratio_a_temp = gain_a / split_info_a\n",
    "#             if gain_ratio_a < gain_ratio_a_temp:\n",
    "#                 gain_ratio_a = gain_ratio_a_temp\n",
    "#                 sel_cut_point = curr_cut_point\n",
    "#             print(f'For cut_point: {curr_cut_point}, inf_d_tot: {inf_d_tot}, inf_d_a: {inf_d_a}, gain_a: {gain_a}, split_info_a: {split_info_a}, gain_ratio: {gain_ratio_a_temp}')\n",
    "            \n",
    "    return (gain_ratio_a, sel_cut_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "cols: [(nom_col, True), (nom_col1, True), (nom_col2, False) ... ]  ........ True if categorical, Otherwise False\n",
    "'''\n",
    "def select_best_column(df, tgt_col='target', cols=[]):\n",
    "    best_param = ('None', 0, 0)\n",
    "    rand_cols = random.choices(cols, k=2)\n",
    "    print(f'rand_cols: {rand_cols}')\n",
    "    for col in rand_cols:\n",
    "        curr_entr, cut_point = get_gain_ratio(df, TGT_COL=tgt_col, EVAL_COL=col[0], CATEGORICAL=col[1])\n",
    "        if best_param[2] <= curr_entr:\n",
    "            best_param = (col[0], cut_point, curr_entr)\n",
    "    return best_param\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Dataset at 0x7fd9f4353ef0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INPUT_PATH = 'data/own_test_benchmark/test_benchmark.csv'\n",
    "STRUCTURE_PATH = 'data/own_test_benchmark/metadata.yaml'\n",
    "obj = Dataset(INPUT_PATH, STRUCTURE_PATH, ';', 'target')\n",
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Tempo', True),\n",
       " ('Temperatura', True),\n",
       " ('Umidade', True),\n",
       " ('Ventoso', True),\n",
       " ('Probabilidade', False)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = []\n",
    "cols = cols + (list(zip([j['name'] for j in obj.categorical_features], [True for i in range(len(obj.categorical_features))])))\n",
    "cols = cols + (list(zip([j['name'] for j in obj.continuous_features], [False for i in range(len(obj.continuous_features))])))\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rand_cols: [('Umidade', True), ('Ventoso', True)]\n",
      "Umidade:   inf_d_tot: 0.9402859586706309, inf_d_a: 0.7884504573082896, gain_a: 0.15183550136234136, split_info_a: 1.0, gain_ratio: 0.15183550136234136\n",
      "Ventoso:   inf_d_tot: 0.9402859586706309, inf_d_a: 0.8921589282623617, gain_a: 0.04812703040826927, split_info_a: 0.9852281360342515, gain_ratio: 0.0488486155115206\n",
      "best_param: ('Umidade', None, 0.15183550136234136)\n",
      "rand_cols: [('Ventoso', True), ('Ventoso', True)]\n",
      "Ventoso:   inf_d_tot: 0.9852281360342515, inf_d_a: 0.9649839288804954, gain_a: 0.020244207153756077, split_info_a: 0.9852281360342515, gain_ratio: 0.020547735507476704\n",
      "Ventoso:   inf_d_tot: 0.9852281360342515, inf_d_a: 0.9649839288804954, gain_a: 0.020244207153756077, split_info_a: 0.9852281360342515, gain_ratio: 0.020547735507476704\n",
      "best_param: ('Ventoso', None, 0.020547735507476704)\n",
      "rand_cols: [('Temperatura', True), ('Temperatura', True)]\n",
      "Temperatura:   inf_d_tot: 1.0, inf_d_a: 1.0, gain_a: 0.0, split_info_a: 1.0, gain_ratio: 0.0\n",
      "Temperatura:   inf_d_tot: 1.0, inf_d_a: 1.0, gain_a: 0.0, split_info_a: 1.0, gain_ratio: 0.0\n",
      "best_param: ('None', 0, 0)\n",
      "new_cols: [('Tempo', True), ('Temperatura', True), ('Probabilidade', False)]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'None'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2645\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2646\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'None'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-f50bb7f36feb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m \u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'target'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0mroot_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-f50bb7f36feb>\u001b[0m in \u001b[0;36mbuild_tree\u001b[0;34m(parent_node, df, tgt_col, cols)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_uniq_vals\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                 \u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'best_param: {best_param}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-f50bb7f36feb>\u001b[0m in \u001b[0;36mbuild_tree\u001b[0;34m(parent_node, df, tgt_col, cols)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtgt_uniq_vals\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                 \u001b[0mbuild_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtgt_col\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'best_param: {best_param}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-44-f50bb7f36feb>\u001b[0m in \u001b[0;36mbuild_tree\u001b[0;34m(parent_node, df, tgt_col, cols)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;34m''' Left child '''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mdf_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbest_param\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_param\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0mdata_temp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'is_leaf'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'answer'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'column'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbest_param\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'value_to_check'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbest_param\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'check_less'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mtgt_uniq_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_temp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtgt_col\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2798\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2799\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2800\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2802\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2646\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2647\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2648\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2649\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2650\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'None'"
     ]
    }
   ],
   "source": [
    "# del data_root, root_node\n",
    "data_root = {'is_leaf': False, 'answer': None, 'column': None, 'value_to_check': None, 'check_less': None}\n",
    "    \n",
    "root_node = Node(data_root)\n",
    "\n",
    "def build_tree(parent_node, df, tgt_col, cols):\n",
    "#     print(df)\n",
    "    # (col_name, cut_point, score)\n",
    "    best_param = select_best_column(df, tgt_col=tgt_col, cols=cols)\n",
    "    print(f'best_param: {best_param}')\n",
    "    '''Numerical'''\n",
    "    if best_param[1] is not None: # Numerical\n",
    "        parent_node.set_children_type('N')\n",
    "        \n",
    "        new_cols = []\n",
    "        for c in cols:\n",
    "            if c[0] != best_param[0]:\n",
    "                new_cols.append(c)\n",
    "        print(f'new_cols: {new_cols}')\n",
    "        \n",
    "        ''' Left child '''\n",
    "        df_temp = df[df[best_param[0]] < best_param[1]]\n",
    "        data_temp = {'is_leaf': False, 'answer': None, 'column': best_param[0], 'value_to_check': best_param[1], 'check_less': True}\n",
    "        tgt_uniq_vals = df_temp[tgt_col].unique()\n",
    "\n",
    "        if (len(tgt_uniq_vals) == 1):  # Is leaf\n",
    "            data_temp['is_leaf'] = True\n",
    "            data_temp['answer'] = tgt_uniq_vals[0]\n",
    "\n",
    "        node_temp = Node(data_temp)\n",
    "        parent_node.insert_node(node_temp)\n",
    "\n",
    "        if (len(tgt_uniq_vals) > 1):\n",
    "            build_tree(node_temp, df_temp, tgt_col, new_cols)\n",
    "            \n",
    "        ''' Right child '''\n",
    "        df_temp = df[df[best_param[0]] >= best_param[1]]\n",
    "        data_temp = {'is_leaf': False, 'answer': None, 'column': best_param[0], 'value_to_check': best_param[1], 'check_less': False}\n",
    "        tgt_uniq_vals = df_temp[tgt_col].unique()\n",
    "\n",
    "        if (len(tgt_uniq_vals) == 1):  # Is leaf\n",
    "            data_temp['is_leaf'] = True\n",
    "            data_temp['answer'] = tgt_uniq_vals[0]\n",
    "\n",
    "        node_temp = Node(data_temp)\n",
    "        parent_node.insert_node(node_temp)\n",
    "\n",
    "        if (len(tgt_uniq_vals) > 1):\n",
    "            build_tree(node_temp, df_temp, tgt_col, new_cols)\n",
    "    else:\n",
    "        '''Categorical'''\n",
    "        parent_node.set_children_type('C')\n",
    "        uniq_vals = df[best_param[0]].unique()\n",
    "        \n",
    "        new_cols = []\n",
    "        for c in cols:\n",
    "            if c[0] != best_param[0]:\n",
    "                new_cols.append(c)\n",
    "#         print(f'new_cols: {new_cols}')\n",
    "        \n",
    "        for val in uniq_vals:\n",
    "            df_temp = df[df[best_param[0]] == val]\n",
    "            data_temp = {'is_leaf': False, 'answer': None, 'column': best_param[0], 'value_to_check': val, 'check_less': None}\n",
    "            tgt_uniq_vals = df_temp[tgt_col].unique()\n",
    "            \n",
    "            if (len(tgt_uniq_vals) == 1):  # Is leaf\n",
    "                data_temp['is_leaf'] = True\n",
    "                data_temp['answer'] = tgt_uniq_vals[0]\n",
    "            \n",
    "            node_temp = Node(data_temp)\n",
    "            parent_node.insert_node(node_temp)\n",
    "            \n",
    "            if (len(tgt_uniq_vals) > 1):\n",
    "                build_tree(node_temp, df_temp, tgt_col, new_cols)\n",
    "        \n",
    "    print(f'best_param: {best_param}')\n",
    "\n",
    "\n",
    "build_tree(root_node, obj.data.copy(), 'target', cols)\n",
    "root_node.print_tree(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_check: Umidade\n",
      "feature_check: Tempo\n",
      "feature_check: Tempo\n",
      "feature_check: Tempo\n",
      "feature_check: Ventoso\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Sim'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "row = {'Tempo': 'Chuvoso', 'Temperatura': 'Amena', 'Umidade': 'Alta', 'Ventoso': 'Falso', 'Probabilidade': 16}\n",
    "root_node.get_classification(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
