{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import numpy as np\n",
    "import random\n",
    "from math import log2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    data = pd.DataFrame()\n",
    "    categorical_features = []\n",
    "    continuous_features = []\n",
    "    yaml_structure = {}\n",
    "    target_feature = ''\n",
    "    target_type = ''\n",
    "\n",
    "    '''\n",
    "    Load the CSV/TSV file, saves it in data\n",
    "    '''\n",
    "    def load_dataset(self, input_path, separator):\n",
    "        self.data = pd.read_csv(input_path, sep=separator)\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    Read the structure and get the types of the columns in two list [categorical, coninuous]\n",
    "    Set target_column and target_type\n",
    "    '''\n",
    "    def read_structure(self, input_file, target_column):\n",
    "        with open(input_file) as f:\n",
    "            self.yaml_structure = yaml.load(f, Loader=yaml.FullLoader)\n",
    "        self.target_feature = target_column\n",
    "        self.target_type = self.yaml_structure['target']['type']\n",
    "        \n",
    "        self.categorical_features = []\n",
    "        self.continuous_features = []\n",
    "        \n",
    "        for feature in self.yaml_structure['features']:\n",
    "            if feature['type'] == 'continuous':\n",
    "                self.continuous_features.append(feature['name'])\n",
    "            else:\n",
    "                self.categorical_features.append(feature['name'])\n",
    "\n",
    "    \n",
    "    '''\n",
    "    Initialization\n",
    "    '''\n",
    "    def __init__(self, file_dataset_path, file_structure_path, char_separator='\\t', target_column='target'):\n",
    "        self.load_dataset(file_dataset_path, char_separator)\n",
    "        self.read_structure(file_structure_path, target_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Boostrap(data):\n",
    "    [m,n] = data.shape\n",
    "    index_train = [] # index set of training set\n",
    "    index_test  = [] # index set of test set\n",
    "    tol = 0\n",
    "    data_split = {'train':index_train, 'test': index_test} # set that contain train and test set split of Dataset\n",
    "    while tol<100:\n",
    "        for i in range(0,m):\n",
    "            index_train.append(np.random.randint(0, m))\n",
    "        for i in range(0,m):\n",
    "            try:\n",
    "                index_train.index(i)\n",
    "            except:\n",
    "                index_test.append(i)\n",
    "        \n",
    "        if len(index_test)<=round(0.35*m):\n",
    "                tol =100\n",
    "        else:\n",
    "            index_train = []\n",
    "            index_test  = []\n",
    "            if tol == 99:\n",
    "                print(tol)\n",
    "                tol = 0\n",
    "        tol = tol+1\n",
    "\n",
    "    data_split['train'] = data.iloc[index_train]\n",
    "    data_split['test']  = data.iloc[index_test]\n",
    "    return data_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_PATH = 'data/wine_recognition/wine-recognition.tsv'\n",
    "STRUCTURE_PATH = 'data/wine_recognition/metadata.yaml'\n",
    "obj = Dataset(INPUT_PATH, STRUCTURE_PATH, '\\t', 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def K_folds(data,k): # Split a group in k- subgroups\n",
    "        N = data.shape[0]\n",
    "        index = np.random.randint(0, N,size=N)\n",
    "        n_folds = N//k\n",
    "        idfold = np.arange(0,N,n_folds)\n",
    "        k_folds = {}\n",
    "        for i in range(0,k):\n",
    "            if i == k-1:\n",
    "                k_folds[i] = data.iloc[index[idfold[i]:N]]\n",
    "            else:\n",
    "                k_folds[i] = data.iloc[index[idfold[i]:idfold[i+1]]]\n",
    "        return k_folds\n",
    "    \n",
    "def K_folds_final(k_folds,k): # Takes k-1 folds for training, and the remaining fold for testing\n",
    "        date_fold = {}\n",
    "        temp = {}\n",
    "        aux = 0\n",
    "        for i in range(0,k):\n",
    "            for j in range(0,k):\n",
    "                if i != j:\n",
    "                    temp[aux] = k_folds[j]\n",
    "                    aux = aux + 1\n",
    "\n",
    "            date_fold[i] = {'train': temp, 'test': k_folds[i]}\n",
    "            temp={}\n",
    "            aux = 0\n",
    "        for i in range(0,k):\n",
    "            a = date_fold[i]\n",
    "            b = a['train']\n",
    "            c = b[0]\n",
    "            for j in range(1,k-1):\n",
    "                c = np.append(c,b[j],axis=0)\n",
    "            date_fold[i]['train']=c    \n",
    "        return date_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-fold cross-validation stratified\n",
    "# c1: represent the one class(ceros)\n",
    "c1 = obj.data[obj.data.target==1]\n",
    "# c2: represent the two class(ones)\n",
    "c2 = obj.data[obj.data.target==2]\n",
    "# c3: represent the two class(ones)\n",
    "c3 = obj.data[obj.data.target==3]\n",
    "\n",
    "k = 10 # number of split of the k-folds\n",
    "\n",
    "k_folds_c1 = K_folds(c1,k) # Split of c1 in k=folds\n",
    "k_folds_c2 = K_folds(c2,k) # Split of c2 in k=folds\n",
    "k_folds_c3 = K_folds(c3,k) # Split of c3 in k=folds\n",
    "k_folds = {} # represent of k-fold cross-validation stratified total\n",
    "for i in range(0,k):\n",
    "        k_folds[i] = np.append(np.append(k_folds_c1[i],k_folds_c2[i],axis=0),k_folds_c3[i],axis=0)\n",
    "\n",
    "\n",
    "k_folds_final = K_folds_final(k_folds,k) # contains all test and training combinations of the k groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "162 16\n",
      "162 16\n",
      "162 16\n",
      "162 16\n",
      "162 16\n",
      "162 16\n",
      "162 16\n",
      "162 16\n",
      "162 16\n",
      "144 34\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(len(k_folds_final[i]['train']),len(k_folds_final[i]['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of the dateset\n",
    "[m,n] = obj.data.shape\n",
    "#data_slt = Boostrap(m,obj.data)\n",
    "#print(datas['train'])\n",
    "#print('#########%%%%%%%%%%%%')\n",
    "#print(datas['test'])\n",
    "# Set that contain s boostrap slpited in train and test set\n",
    "S_data_boostrap = {}\n",
    "S_data_boostrap_total = {}\n",
    "for j in range(k):\n",
    "    aux = pd.DataFrame(k_folds_final[j]['train'])\n",
    "    for i in range(0,50):\n",
    "        S_data_boostrap[i] = Boostrap(aux)\n",
    "        #print('########################')\n",
    "        #print(len(S_data_boostrap[i]['train']))\n",
    "        #print(len(S_data_boostrap[i]['test']))\n",
    "        #print('%%%%%%%%%%%%%%%%%%%%%%%%')\n",
    "    S_data_boostrap_total[j]={'train': S_data_boostrap, 'test': pd.DataFrame(k_folds_final[j]['test'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      0      1     2     3     4      5     6     7     8     9     10    11  \\\n",
      "0    1.0  14.39  1.87  2.45  14.6   96.0  2.50  2.52  0.30  1.98  5.25  1.02   \n",
      "2    1.0  13.05  1.73  2.04  12.4   92.0  2.72  3.27  0.17  2.91  7.20  1.12   \n",
      "3    1.0  13.76  1.53  2.70  19.5  132.0  2.95  2.74  0.50  1.35  5.40  1.25   \n",
      "5    2.0  11.96  1.09  2.30  21.0  101.0  3.38  2.14  0.13  1.65  3.21  0.99   \n",
      "7    2.0  12.04  4.30  2.38  22.0   80.0  2.10  1.75  0.42  1.35  2.60  0.79   \n",
      "15   3.0  13.17  5.19  2.32  22.0   93.0  1.74  0.63  0.61  1.55  7.90  0.60   \n",
      "19   1.0  14.22  1.70  2.30  16.3  118.0  3.20  3.00  0.26  2.03  6.38  0.94   \n",
      "21   2.0  12.21  1.19  1.75  16.8  151.0  1.85  1.28  0.14  2.50  2.85  1.28   \n",
      "23   2.0  12.77  3.43  1.98  16.0   80.0  1.63  1.25  0.43  0.83  3.40  0.70   \n",
      "25   2.0  12.64  1.36  2.02  16.8  100.0  2.02  1.41  0.53  0.62  5.75  0.98   \n",
      "26   2.0  11.65  1.67  2.62  26.0   88.0  1.92  1.61  0.40  1.34  2.60  1.36   \n",
      "28   3.0  12.51  1.24  2.25  17.5   85.0  2.00  0.58  0.60  1.25  5.45  0.75   \n",
      "29   3.0  14.16  2.51  2.48  20.0   91.0  1.68  0.70  0.44  1.24  9.70  0.62   \n",
      "30   3.0  13.17  2.59  2.37  20.0  120.0  1.65  0.68  0.53  1.46  9.30  0.60   \n",
      "32   1.0  13.29  1.97  2.68  16.8  102.0  3.00  3.23  0.31  1.66  6.00  1.07   \n",
      "34   1.0  13.05  1.65  2.55  18.0   98.0  2.45  2.43  0.29  1.44  4.25  1.12   \n",
      "37   2.0  11.64  2.06  2.46  21.6   84.0  1.95  1.69  0.48  1.35  2.80  1.00   \n",
      "40   2.0  11.41  0.74  2.50  21.0   88.0  2.48  2.01  0.42  1.44  3.08  1.10   \n",
      "44   3.0  13.32  3.24  2.38  21.5   92.0  1.93  0.76  0.45  1.25  8.42  0.55   \n",
      "46   3.0  12.51  1.24  2.25  17.5   85.0  2.00  0.58  0.60  1.25  5.45  0.75   \n",
      "53   2.0  12.17  1.45  2.53  19.0  104.0  1.89  1.75  0.45  1.03  2.95  1.45   \n",
      "56   2.0  12.08  1.39  2.50  22.5   84.0  2.56  2.29  0.43  1.04  2.90  0.93   \n",
      "58   2.0  13.67  1.25  1.92  18.0   94.0  2.10  1.79  0.32  0.73  3.80  1.23   \n",
      "64   1.0  14.39  1.87  2.45  14.6   96.0  2.50  2.52  0.30  1.98  5.25  1.02   \n",
      "70   2.0  13.67  1.25  1.92  18.0   94.0  2.10  1.79  0.32  0.73  3.80  1.23   \n",
      "71   2.0  13.05  3.86  2.32  22.5   85.0  1.65  1.59  0.61  1.62  4.80  0.84   \n",
      "72   2.0  12.34  2.45  2.46  21.0   98.0  2.56  2.11  0.34  1.31  2.80  0.80   \n",
      "73   2.0  12.42  4.43  2.73  26.5  102.0  2.20  2.13  0.43  1.71  2.08  0.92   \n",
      "75   2.0  12.29  2.83  2.22  18.0   88.0  2.45  2.25  0.25  1.99  2.15  1.15   \n",
      "78   3.0  12.87  4.61  2.48  21.5   86.0  1.70  0.65  0.47  0.86  7.65  0.54   \n",
      "80   1.0  14.21  4.04  2.44  18.9  111.0  2.85  2.65  0.30  1.25  5.24  0.87   \n",
      "91   2.0  12.47  1.52  2.20  19.0  162.0  2.50  2.27  0.32  3.28  2.60  1.16   \n",
      "95   3.0  12.53  5.51  2.64  25.0   96.0  1.79  0.60  0.63  1.10  5.00  0.82   \n",
      "96   1.0  12.85  1.60  2.52  17.8   95.0  2.48  2.37  0.26  1.46  3.93  1.09   \n",
      "97   1.0  14.12  1.48  2.32  16.8   95.0  2.20  2.43  0.26  1.57  5.00  1.17   \n",
      "99   1.0  13.56  1.71  2.31  16.2  117.0  3.15  3.29  0.34  2.34  6.13  0.95   \n",
      "103  2.0  11.41  0.74  2.50  21.0   88.0  2.48  2.01  0.42  1.44  3.08  1.10   \n",
      "104  2.0  12.21  1.19  1.75  16.8  151.0  1.85  1.28  0.14  2.50  2.85  1.28   \n",
      "105  2.0  12.33  1.10  2.28  16.0  101.0  2.05  1.09  0.63  0.41  3.27  1.25   \n",
      "107  2.0  11.45  2.40  2.42  20.0   96.0  2.90  2.79  0.32  1.83  3.25  0.80   \n",
      "110  3.0  12.25  4.72  2.54  21.0   89.0  1.38  0.47  0.53  0.80  3.85  0.75   \n",
      "112  1.0  14.12  1.48  2.32  16.8   95.0  2.20  2.43  0.26  1.57  5.00  1.17   \n",
      "133  2.0  12.08  1.13  2.51  24.0   78.0  2.00  1.58  0.40  1.40  2.20  1.31   \n",
      "137  2.0  12.29  1.41  1.98  16.0   85.0  2.55  2.50  0.29  1.77  2.90  1.23   \n",
      "138  2.0  11.62  1.99  2.28  18.0   98.0  3.02  2.26  0.17  1.35  3.25  1.16   \n",
      "143  3.0  13.32  3.24  2.38  21.5   92.0  1.93  0.76  0.45  1.25  8.42  0.55   \n",
      "\n",
      "       12      13  \n",
      "0    3.58  1290.0  \n",
      "2    2.91  1150.0  \n",
      "3    3.00  1235.0  \n",
      "5    3.13   886.0  \n",
      "7    2.57   580.0  \n",
      "15   1.48   725.0  \n",
      "19   3.31   970.0  \n",
      "21   3.07   718.0  \n",
      "23   2.12   372.0  \n",
      "25   1.59   450.0  \n",
      "26   3.21   562.0  \n",
      "28   1.51   650.0  \n",
      "29   1.71   660.0  \n",
      "30   1.62   840.0  \n",
      "32   2.84  1270.0  \n",
      "34   2.51  1105.0  \n",
      "37   2.75   680.0  \n",
      "40   2.31   434.0  \n",
      "44   1.62   650.0  \n",
      "46   1.51   650.0  \n",
      "53   2.23   355.0  \n",
      "56   3.19   385.0  \n",
      "58   2.46   630.0  \n",
      "64   3.58  1290.0  \n",
      "70   2.46   630.0  \n",
      "71   2.01   515.0  \n",
      "72   3.38   438.0  \n",
      "73   3.12   365.0  \n",
      "75   3.30   290.0  \n",
      "78   1.86   625.0  \n",
      "80   3.33  1080.0  \n",
      "91   2.63   937.0  \n",
      "95   1.69   515.0  \n",
      "96   3.63  1015.0  \n",
      "97   2.82  1280.0  \n",
      "99   3.38   795.0  \n",
      "103  2.31   434.0  \n",
      "104  3.07   718.0  \n",
      "105  1.67   680.0  \n",
      "107  3.39   625.0  \n",
      "110  1.27   720.0  \n",
      "112  2.82  1280.0  \n",
      "133  2.72   630.0  \n",
      "137  2.74   428.0  \n",
      "138  2.96   345.0  \n",
      "143  1.62   650.0  \n"
     ]
    }
   ],
   "source": [
    "print(S_data_boostrap_total[2]['train'][0]['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
